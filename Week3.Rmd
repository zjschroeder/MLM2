---
title: "Week 3"
author: "Zach Schroeder"
date: "4/16/2021"
output: html_document
editor_options: 
  chunk_output_type: console
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r}
library(tidyverse)
library(lme4)
library(performance)
```

```{r}
popular <- read_csv(here::here("data", "popularity.csv"))
popular
```

Models
```{r}
m0 <- lmer(popular ~ 1 + (1|class), popular)
m1 <- lmer(popular ~ sex + (1|class), popular)
m2 <- lmer(popular ~ sex + (sex|class), popular)
```

Comparing performance
```{r}
compare_performance(m0, m1, m2) %>% 
  print_md()
```

Marginal R^2 suggests that m1 is a better fit than m2, as the adjustment the marginal r2 makes did not increase in explanatory power.

Package Options:
Broom: we love broom, cleans stuff, is nice
Paramaters (in easystats) is also fun

```{r}
library(broom.mixed)
tidy(m0)
```

Tidying a bunch of models:
```{r}
models <- bind_rows(
  tidy(m0, effects = "fixed", conf.int = TRUE),
  tidy(m1, effects = "fixed", conf.int = TRUE),
  tidy(m2, effects = "fixed", conf.int = TRUE),
  .id = "model"
  ) %>% 
  mutate(model = as.numeric(model) - 1)
models
```

Plotting plots
We LOVE broom.mixed because the code below will ALWAYS WORK
```{r}
pd <- position_dodge(0.5)
ggplot(models, aes(estimate, term, color = factor(model))) +
  geom_errorbarh(aes(xmin = conf.low, xmax = conf.high), 
                 position = pd,
                 height = 0.2) +
  geom_point(position = pd)
```

Bootstrapping the models for CIs, mapping uncertainty
Used DA's function writing tip
```{r}
pull_model_results <- function(model) {
  tidy(
    model,
    conf.int = TRUE, 
    conf.method = "boot"
  )
}
full_models <- bind_rows(
  pull_model_results(m0),
  pull_model_results(m1),
  pull_model_results(m2),
  .id = "model"
)

ggplot(full_models, aes(estimate, term, color = factor(model))) +
  geom_errorbarh(aes(xmin = conf.low, xmax = conf.high), 
                 position = pd,
                 height = 0.2) +
  geom_point(position = pd) +
  facet_wrap(~effect, scales = "free_y") +
  theme(legend.position = "bottom")
```

POP QUIZ:

Ran coefs: pulls ran_vals AND the intercept. So, we have fixed effects PLUS random variation around the fixed effects, as estimatedy by ran_coefs.

```{r}
m0_ranvals <- tidy(m0, effects = "ran_vals", conf.int = TRUE)
m0_ranvals %>% 
  mutate(level = reorder(factor(level), estimate)) %>% #this reorders to level
  ggplot(aes(level, estimate)) +
  geom_errorbar(aes(ymin = conf.low, ymax = conf.high),
                width = 0.5) +
  geom_point() +
  geom_hline(yintercept = 0, size = 2, color = "magenta")
```

WRAPPING UP COEF PLOTS:
Coefficient plots are generally fairly easy to produce, but often not the most informative

Random effects plots (like the one above) are probs more informative than the fixed effects/variance components plots

e.g., we can see that most of the points do not have CIs that cross the 0 line, suggesting our model is #real

Predicting by hand:
```{r}
#Extract the random values
m2_ranvals <- tidy(m2, effects = "ran_vals")
class1_ranvals <- m2_ranvals %>% 
  filter(group == "class" & level == 1)
class1_ranvals
# Extract the mixed effects
fixef(m2)[1] + fixef(m2)[2]*(popular[1, ]$sex == "girl") +
  class1_ranvals$estimate[1] + class1_ranvals$estimate[2]
```

Challenge
```{r}
class10_ranvals <- m2_ranvals %>% 
  filter(group == "class" & level == 10)
fixef(m2)[1] + class10_ranvals$estimate[1]
```

This is a lot of typing, so instead, let's use the predict function

```{r}
library(equatiomatic)
data <- sim_longitudinal
```
Model
```{r}
mod <- lmer(score ~ wave + treatment + (wave|sid),
            data = data)
```

Plot predictions
First, ungrouping in order to limit to first three students, then graphing to show differences between prediction and outcome
```{r}
first_three <- sim_longitudinal %>% 
  ungroup() %>%
  filter(sid %in% 1:3)

first_three <- first_three %>% 
  mutate(model_pred = predict(mod, newdata = first_three))

ggplot(data = first_three) +
  geom_line(aes(x = wave, y = score, color = treatment)) +
  geom_line(aes(x = wave, y = model_pred, color = treatment)) +
  facet_wrap(~sid)
```

CHecking what it would look like for student 2 to be in treatment group

```{r}
stu2 <- data.frame(
  sid = 2,
  wave = 2:9,
  treatment = factor("1", levels = c(0,1))
)

predict(mod, newdata = stu2)
# GRAPHING from DA
sim_longitudinal %>% 
  filter(sid == 2) %>% 
  mutate(model_pred = predict(mod, newdata = .),
         trt_pred = predict(mod, newdata = stu2)) %>% 
  ggplot(aes(wave, score)) +
  geom_point() +
  geom_line() +
  geom_line(aes(y = model_pred)) +
  geom_line(aes(y = trt_pred),
            color = "firebrick") +
  annotate(
    "text", 
    x = 6, 
    y = 81, 
    hjust = 0, 
    color = "firebrick", 
    label = "Predicted slope if student\nwas in treatment group"
  )
```

# UNCERTAINTY

Specific predictions!

```{r}
pred_frame <- data.frame(
  sid = rep(1:3, each = 13), #REMEMBER THSI because this is half of the stuff I do
  wave = rep(0:12),
  treatment = factor(rep(c(1, 0, 1), each = 13))
)

library(merTools)
m_pred_interval <- predictInterval(
  mod, 
  newdata = pred_frame, 
  level = 0.95
)

bind_cols(pred_frame, m_pred_interval)  %>% 
  ggplot(aes(wave, fit)) +
  geom_ribbon(aes(ymin = lwr, ymax = upr),
              alpha = 0.4) +
  geom_line(color = "magenta") +
  facet_wrap(~sid)
```

Bootstrap Bill

```{r}
pred_fun <- function(fit) {
  predict(fit, newdata = pred_frame)
}
#doing this with lme4, DA no le gusta bootMer
b <- bootMer(
  mod, 
  nsim = 1000, 
  FUN = pred_fun,
  use.u = TRUE, 
  seed = 42
)

# lots of code from DA on turnign this into a dataframe
bd <- as.data.frame(t(b$t)) %>% 
  mutate(sid = rep(1:3, each = 13),
         wave = rep(0:12, 3)) %>% 
  pivot_longer(
    starts_with("V"),
    names_to = "bootstrap_sample",
    names_prefix = "V",
    names_transform = list(bootstrap_sample = as.numeric),
    values_to = "score"
  ) %>% 
  arrange(sid, bootstrap_sample, wave)

# We can then graph this
ggplot(bd, aes(wave, score)) +
  geom_line(aes(group = bootstrap_sample),
            size = 0.1,
            alpha = 0.5,
            color = "cornflowerblue") +
  facet_wrap(~sid)

#Do this with ribbons
bd_ribbons <- bd %>% 
  group_by(sid, wave) %>% 
  summarize(quantile = quantile(score, c(0.025, 0.975)),
            group = c("lower", "upper")) %>% 
  pivot_wider(names_from = "group", values_from = "quantile")

# Join with real data
bd_ribbons <- left_join(first_three, bd_ribbons) %>% 
  mutate(pred = predict(mod, newdata = first_three))

# So, we can plot again;
ggplot(bd_ribbons, aes(wave, score)) +
  geom_ribbon(aes(ymin = lower, ymax = upper),
              alpha = 0.5) +
  geom_line(aes(y = pred), size = 1, color = "magenta") +
  geom_point() +
  facet_wrap(~sid)
```

# INTERACTIONS
```{r}
m1a <- lmer(score ~ wave*treatment + 
              (wave|sid) + (1|school),
            data = sim_longitudinal)
```

The above uses implicit nesting, need to make it explicit (wave|sid:school) + (1|school) if I don't have unique IDs

And then I had problems following some of the graphing and marginal effects, but think I've got a good grasp on it.
